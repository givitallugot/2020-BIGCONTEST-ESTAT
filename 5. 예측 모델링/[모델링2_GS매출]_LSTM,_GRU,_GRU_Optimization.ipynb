{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "FwFRnV1Oyjz6",
    "outputId": "cec06d21-c79e-41eb-f5e3-659134689eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "9n0oBsBJ7LQR",
    "outputId": "cce1e81b-5e96-40d6-c623-2f1d5f577a83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "import matplotlib.font_manager as fm\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPsqFuyz3ndR"
   },
   "outputs": [],
   "source": [
    "#!sudo apt-get install -y fonts-nanum\n",
    "#!sudo fc-cache -fv\n",
    "#!rm ~/.cache/matplotlib -rf\n",
    "\n",
    "plt.rc('font', family='NanumBarunGothic') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjS7ubtw8A74"
   },
   "source": [
    "# **0.데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ey3ouj2YNs44"
   },
   "outputs": [],
   "source": [
    "final_data = pd.read_csv('./gdrive/My Drive/빅콘 대상팀/data/model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJbgAPj8Nuvr"
   },
   "outputs": [],
   "source": [
    "gu = pd.read_excel('./gdrive/My Drive/빅콘 대상팀/data/지역데이터/구_동.xlsx')\n",
    "gs = pd.read_csv('./gdrive/My Drive/빅콘 대상팀/data/all_amt.csv',parse_dates=['STD_YMD'])\n",
    "#gs = gs.drop(['Unnamed: 0'],axis=1)\n",
    "gs = pd.concat([gs.iloc[:,[0,1]],gs.filter(like='GS')],axis=1)\n",
    "gs = pd.merge(gs,gu,on='HDONG_NM')\n",
    "gs['CITY'] = gs['HDONG_GU'].apply(lambda x: x[0:2])\n",
    "gs_seoul = gs.query('CITY == \"서울\" & STD_YMD > \"2020\"')\n",
    "\n",
    "gs_eat = gs_seoul.iloc[:,[0,1,3]].sort_values(['HDONG_NM','STD_YMD'])\n",
    "gs_snack = gs_seoul.iloc[:,[0,1,4]].sort_values(['HDONG_NM','STD_YMD'])\n",
    "gs_drink = gs_seoul.iloc[:,[0,1,5]].sort_values(['HDONG_NM','STD_YMD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6oRtXtQNxZN"
   },
   "outputs": [],
   "source": [
    "final_data4 = final_data.drop(['COVID_CNT','covid_p1','sc_m1','cj_m1','covid_p1','최저기온','최고기온','일강수량'],axis=1) #최종사용데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbz7aTK1U3ZE"
   },
   "outputs": [],
   "source": [
    "def build_data(data,dong,cat):\n",
    "\n",
    "  X = data.query('HDONG_NM==@dong').reset_index(drop=True)\n",
    "  \n",
    "  if cat == \"식사\":\n",
    "    eat = gs_eat.query('HDONG_NM==@dong').reset_index(drop=True)\n",
    "    X['self_m7'] = eat['GS_식사'].shift(7)\n",
    "    X['y'] = eat['GS_식사']\n",
    "  elif cat == \"간식\":\n",
    "    snack = gs_snack.query('HDONG_NM==@dong').reset_index(drop=True)\n",
    "    X['self_m7'] = snack['GS_간식'].shift(7)\n",
    "    X['y'] = snack['GS_간식']\n",
    "  elif cat == \"마실거리\":\n",
    "    drink = gs_drink.query('HDONG_NM==@dong').reset_index(drop=True)\n",
    "    X['self_m7'] = drink['GS_마실거리'].shift(7)\n",
    "    X['y'] = drink['GS_마실거리']\n",
    "  \n",
    "  X.index = X['STD_YMD']\n",
    "  del X['STD_YMD'],X['HDONG_NM']\n",
    "\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kO-iR5eXtBeV"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "def minmax_scalar(X):\n",
    "  idx = X.index\n",
    "  col = X.columns\n",
    "\n",
    "  scalar = MinMaxScaler()\n",
    "  scaled_X = pd.DataFrame(scalar.fit_transform(X))\n",
    "  scaled_X.index = idx\n",
    "  scaled_X.columns = col\n",
    "\n",
    "  return scaled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "not2CAZTSy4w"
   },
   "outputs": [],
   "source": [
    "def split_xy(dataset, time_steps, y_column):\n",
    "\n",
    "  x, y = list(), list()\n",
    "  for i in range(len(dataset)):\n",
    "    x_end_number = i + time_steps\n",
    "    y_end_number = x_end_number + y_column\n",
    "\n",
    "    if y_end_number > len(dataset):\n",
    "      break\n",
    "    tmp_x = np.array(dataset)[i:x_end_number, :]\n",
    "    tmp_y = np.array(dataset)[x_end_number:y_end_number, -1]\n",
    "    x.append(tmp_x)\n",
    "    y.append(tmp_y)\n",
    "  return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OF4-zsRWqHVb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def RMSLE_fun(origin,pred):\n",
    "  rmsle = np.sqrt(mean_squared_log_error(origin+1, pred+1))\n",
    "  return rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsHb-LirBKA6"
   },
   "outputs": [],
   "source": [
    "def train_test_split(n,X,y):\n",
    "  if isinstance(X, pd.DataFrame):\n",
    "    total = X.shape[0]\n",
    "    X_train,X_test = X.iloc[:total-n, :],X.iloc[-n:, :]\n",
    "    y_train,y_test = y[:total-n],y[-n:]\n",
    "  else :\n",
    "    total = X.shape[0]\n",
    "    X_train,X_test = X[:total-n, :],X[-n:, :]\n",
    "    y_train,y_test = y[:total-n],y[-n:]\n",
    "  return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErzrjpgTst6p"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SElM7Bm3Yaut"
   },
   "outputs": [],
   "source": [
    "def data_pipeline(data, dong, cat, time_steps, y_columns):\n",
    "  data = build_data(data,dong,cat)\n",
    "  \n",
    "  #y = data['y']\n",
    "  #del data['y']\n",
    "  min = data['y'].min()\n",
    "  max = data['y'].max()\n",
    "\n",
    "  X = minmax_scalar(data)\n",
    "  #Xy = pd.concat([X,y],axis=1)\n",
    "  Xy = X.dropna()\n",
    "  \n",
    "  X,y = split_xy(Xy,time_steps,y_columns)\n",
    "\n",
    "  X_train, y_train = X[:-7],y[:-7]\n",
    "  X_test, y_test = X[-7:],y[-7:]\n",
    "\n",
    "  X_test=X_test.reshape(-1,time_steps,X_train.shape[2])\n",
    "  y_test=y_test.reshape(-1,y_columns)\n",
    "\n",
    "\n",
    "\n",
    "  return X_train,y_train,X_test,y_test,min,max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ux05eKxuhuTu"
   },
   "source": [
    "# **1. LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUZ1row35x0t"
   },
   "outputs": [],
   "source": [
    "def LSTM_fun(data, dong, cat):\n",
    "  \n",
    "  X_train,y_train,X_test,y_test,min,max = data_pipeline(data, dong, cat,7,1)\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(100, input_shape = (None, X_train.shape[2])))\n",
    "  model.add(Dense(10))\n",
    "  model.add(Dense(1))\n",
    "\n",
    "  model.compile(optimizer='adam', loss='mse')\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True)\n",
    "  model.fit(X_train, y_train, epochs=5000, batch_size=32, verbose=0, callbacks=[early_stopping], validation_data = (X_test, y_test))\n",
    "\n",
    "  y_pred = model.predict(X_test, batch_size=1)\n",
    "  #y_pred = y_pred.reshape(-1, 1) *(max-min)+min\n",
    "  #y_test = y_test *(max-min)+min\n",
    "\n",
    "  mse = np.mean((y_test-y_pred)**2)\n",
    "  rmse = np.sqrt(mse)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  rmsle = RMSLE_fun(np.array(y_test), np.array(y_pred))\n",
    "\n",
    "  return mse, rmse, mae, rmsle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMdoJEwEdswX"
   },
   "source": [
    "# **2. GRU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09-2xxL5Z0bt"
   },
   "outputs": [],
   "source": [
    "def GRU_fun(data, dong, cat):\n",
    "  \n",
    "  X_train,y_train,X_test,y_test,min,max = data_pipeline(data, dong, cat,7,1)\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(GRU(100, input_shape = (None, X_train.shape[2])))\n",
    "  model.add(Dense(10))\n",
    "  #model.add(Dense(7))\n",
    "  model.add(Dense(1))\n",
    "\n",
    "  model.compile(optimizer='adam', loss='mse')\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', patience=50, mode='min', restore_best_weights=True)\n",
    "  model.fit(X_train, y_train, epochs=5000, batch_size=32, verbose=0, callbacks=[early_stopping], validation_data = (X_test, y_test))\n",
    "\n",
    "  \n",
    "  y_pred = model.predict(X_test, batch_size=1)\n",
    "  #y_pred = y_pred.reshape(-1, 1) *(max-min)+min\n",
    "  #y_test = y_test *(max-min)+min\n",
    "\n",
    "  mse = np.mean((y_test-y_pred)**2)\n",
    "  rmse = np.sqrt(mse)\n",
    "  mae = mean_absolute_error(y_test, y_pred)\n",
    "  rmsle = RMSLE_fun(np.array(y_test), np.array(y_pred))\n",
    "\n",
    "  return mse, rmse, mae, rmsle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zAA3ZEbdx6_"
   },
   "source": [
    "# **3. LSTM & GRU results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fSZg-1tb8m9"
   },
   "outputs": [],
   "source": [
    "dong_list = list(final_data['HDONG_NM'].unique())\n",
    "dong_list.remove('상계8동')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rVhbWTBZmbA"
   },
   "outputs": [],
   "source": [
    "# LSTM\n",
    "MSE_eat = []\n",
    "RMSE_eat = []\n",
    "MAE_eat = []\n",
    "RMSLE_eat = []\n",
    "\n",
    "MSE_snack = []\n",
    "RMSE_snack = []\n",
    "MAE_snack = []\n",
    "RMSLE_snack = []\n",
    "\n",
    "MSE_drink = []\n",
    "RMSE_drink = []\n",
    "MAE_drink = []\n",
    "RMSLE_drink = []\n",
    "\n",
    "for cat in ['식사', '간식', '마실거리']:\n",
    "  for dong in dong_list:\n",
    "    mse, rmse, mae, rmsle = LSTM_fun(final_data4, dong, cat)\n",
    "    #print('{0}, {1}, {2}, {3}, {4}, {5}'.format(dong, cat, mse, rmse, mae, rmsle))\n",
    "\n",
    "    if cat == '식사':\n",
    "      MSE_eat.append(mse)\n",
    "      RMSE_eat.append(rmse)\n",
    "      MAE_eat.append(mae)\n",
    "      RMSLE_eat.append(rmsle)\n",
    "      \n",
    "    elif cat == '간식':\n",
    "      MSE_snack.append(mse)\n",
    "      RMSE_snack.append(rmse)\n",
    "      MAE_snack.append(mae)\n",
    "      RMSLE_snack.append(rmsle)\n",
    "      \n",
    "    else: \n",
    "      MSE_drink.append(mse)\n",
    "      RMSE_drink.append(rmse)\n",
    "      MAE_drink.append(mae)\n",
    "      RMSLE_drink.append(rmsle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwKM8rHOdB6Z"
   },
   "outputs": [],
   "source": [
    "lstm_result = pd.DataFrame({'동':dong_list,\n",
    "              '식사_MSE':MSE_eat,\n",
    "              '식사_RMSE':RMSE_eat,\n",
    "              '식사_MAE':MAE_eat,\n",
    "              '식사_RMSLE':RMSLE_eat,\n",
    "              '간식_MSE':MSE_snack,\n",
    "              '간식_RMSE':RMSE_snack,\n",
    "              '간식_MAE':MAE_snack,\n",
    "              '간식_RMSLE':RMSLE_snack,\n",
    "              '마실거리_MSE':MSE_drink,\n",
    "              '마실거리_RMSE':RMSE_drink,\n",
    "              '마실거리_MAE':MAE_drink,\n",
    "              '마실거리_RMSLE':RMSLE_drink})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "RwvjYeq_rAF4",
    "outputId": "cdbd60a4-5ff6-4997-906b-ab42100108fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "식사_MSE        0.015842\n",
       "식사_RMSE       0.115357\n",
       "식사_MAE        0.096041\n",
       "식사_RMSLE      0.045043\n",
       "간식_MSE        0.006963\n",
       "간식_RMSE       0.072412\n",
       "간식_MAE        0.060080\n",
       "간식_RMSLE      0.031221\n",
       "마실거리_MSE      0.019499\n",
       "마실거리_RMSE     0.126972\n",
       "마실거리_MAE      0.107811\n",
       "마실거리_RMSLE    0.047043\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTWwVWM2ikr_"
   },
   "outputs": [],
   "source": [
    "# GRU\n",
    "MSE_eat = []\n",
    "RMSE_eat = []\n",
    "MAE_eat = []\n",
    "RMSLE_eat = []\n",
    "\n",
    "MSE_snack = []\n",
    "RMSE_snack = []\n",
    "MAE_snack = []\n",
    "RMSLE_snack = []\n",
    "\n",
    "MSE_drink = []\n",
    "RMSE_drink = []\n",
    "MAE_drink = []\n",
    "RMSLE_drink = []\n",
    "\n",
    "for cat in ['식사', '간식', '마실거리']:\n",
    "  for dong in dong_list:\n",
    "    mse, rmse, mae, rmsle = GRU_fun(final_data4, dong, cat)\n",
    "    print('{0}, {1}, {2}, {3}, {4}, {5}'.format(dong, cat, mse, rmse, mae, rmsle))\n",
    "\n",
    "    if cat == '식사':\n",
    "      MSE_eat.append(mse)\n",
    "      RMSE_eat.append(rmse)\n",
    "      MAE_eat.append(mae)\n",
    "      RMSLE_eat.append(rmsle)\n",
    "      \n",
    "    elif cat == '간식':\n",
    "      MSE_snack.append(mse)\n",
    "      RMSE_snack.append(rmse)\n",
    "      MAE_snack.append(mae)\n",
    "      RMSLE_snack.append(rmsle)\n",
    "      \n",
    "    else: \n",
    "      MSE_drink.append(mse)\n",
    "      RMSE_drink.append(rmse)\n",
    "      MAE_drink.append(mae)\n",
    "      RMSLE_drink.append(rmsle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9ggO2tXinqS"
   },
   "outputs": [],
   "source": [
    "gru_result = pd.DataFrame({'동':dong_list,\n",
    "              '식사_MSE':MSE_eat,\n",
    "              '식사_RMSE':RMSE_eat,\n",
    "              '식사_MAE':MAE_eat,\n",
    "              '식사_RMSLE':RMSLE_eat,\n",
    "              '간식_MSE':MSE_snack,\n",
    "              '간식_RMSE':RMSE_snack,\n",
    "              '간식_MAE':MAE_snack,\n",
    "              '간식_RMSLE':RMSLE_snack,\n",
    "              '마실거리_MSE':MSE_drink,\n",
    "              '마실거리_RMSE':RMSE_drink,\n",
    "              '마실거리_MAE':MAE_drink,\n",
    "              '마실거리_RMSLE':RMSLE_drink})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "SIRo1jHgrEPs",
    "outputId": "6d88a600-058d-4cf1-c66f-1a230136339e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "식사_MSE        0.015914\n",
       "식사_RMSE       0.116324\n",
       "식사_MAE        0.097095\n",
       "식사_RMSLE      0.045337\n",
       "간식_MSE        0.006268\n",
       "간식_RMSE       0.068403\n",
       "간식_MAE        0.056125\n",
       "간식_RMSLE      0.029493\n",
       "마실거리_MSE      0.014624\n",
       "마실거리_RMSE     0.111393\n",
       "마실거리_MAE      0.091851\n",
       "마실거리_RMSLE    0.041372\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EiiJo_0ZnxY"
   },
   "source": [
    "# **4. GRU Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WL9nVLewprp"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2NasBltWG_9"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-optimize\n",
    "import skopt\n",
    "\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer  \n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "dim_num_input_nodes = Integer(low=100, high=512, name='num_input_nodes')\n",
    "dim_num_dense_nodes = Integer(low=10, high=50, name='num_dense_nodes')\n",
    "dim_activation = Categorical(categories=['relu', 'sigmoid'],\n",
    "                             name='activation')\n",
    "dim_batch_size = Integer(low=1, high=32, name='batch_size')\n",
    "\n",
    "dimensions = [dim_num_dense_layers,\n",
    "              dim_num_input_nodes,\n",
    "              dim_num_dense_nodes,\n",
    "              dim_activation,\n",
    "              dim_batch_size\n",
    "             ]\n",
    "default_parameters = [1, 512, 13, 'relu',32]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_SfTZXqw3aR"
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "def create_model(num_dense_layers,num_input_nodes,\n",
    "                 num_dense_nodes, activation):\n",
    "    #start the model making process and create our first layer\n",
    "\n",
    "    X_train, y_train, X_test, y_test,_,_ = data_pipeline(final_data4, d, c, 7, 1) \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(GRU(num_input_nodes, input_shape=(None, X_train.shape[2]), activation=activation\n",
    "                   ))\n",
    "    #create a loop making a new dense layer for the amount passed to this model.\n",
    "    #naming the layers helps avoid tensorflow error deep in the stack trace.\n",
    "    for i in range(num_dense_layers):\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                 activation=activation,\n",
    "                        name=name\n",
    "                 ))\n",
    "    #add our classification layer.\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    #setup our optimizer and compile\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtbpDFyK31Kl"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(num_dense_layers, num_input_nodes, \n",
    "            num_dense_nodes,activation, batch_size):\n",
    "  \n",
    "  model = create_model(num_dense_layers=num_dense_layers,\n",
    "                        num_input_nodes=num_input_nodes,\n",
    "                        num_dense_nodes=num_dense_nodes,\n",
    "                        activation=activation\n",
    "                      )\n",
    "  \n",
    "  X_train,y_train,X_test,y_test,min,max = data_pipeline(final_data4, d, c,7,1) \n",
    "  \n",
    "  early_stopping = EarlyStopping(monitor='val_loss', patience=30, mode='min', restore_best_weights=True)\n",
    "  model.fit(X_train, y_train, epochs=5000, batch_size=32, verbose=0, callbacks=[early_stopping], validation_data = (X_test, y_test))\n",
    "\n",
    "  y_pred = model.predict(X_test, batch_size=1)\n",
    "  y_pred = y_pred.reshape(-1,1) *(max-min) + min\n",
    "  y_test = y_test *(max-min) + min\n",
    "\n",
    "  mse = np.mean((y_test-y_pred)**2)\n",
    "  rmse = np.sqrt(mse)\n",
    "\n",
    "  print()\n",
    "  print(\"MSE: {}, RMSE: {}\".format(mse,rmse))\n",
    "  print()\n",
    "\n",
    "  global best_mse\n",
    "  \n",
    "  if mse <= best_mse:\n",
    "      model.save('./gdrive/My Drive/빅콘 대상팀/분석 code/GRU/models/{}{} GRU.hdf5'.format(d,c))\n",
    "      # 각 동별로 optimize 된 모델을 저장하였음.\n",
    "      best_mse = mse\n",
    "\n",
    "  del model\n",
    "  \n",
    "  return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxueOI9c8TzK"
   },
   "outputs": [],
   "source": [
    "for c in ['식사', '간식', '마실거리']:\n",
    "  for d in dong_list:\n",
    "    best_mse=100\n",
    "\n",
    "    gp_result = gp_minimize(func=fitness,\n",
    "                                dimensions=dimensions,\n",
    "                                n_calls=12,\n",
    "                                noise= 0.01,\n",
    "                                n_jobs=-1,\n",
    "                                kappa = 5,\n",
    "                                x0=default_parameters)\n",
    "    \n",
    "    \n",
    "    from skopt import dump, load\n",
    "    dump(gp_result, 'result.pkl')\n",
    "    gp_result_loaded = load('result.pkl')\n",
    "\n",
    "    print('{0} {1}, Best MSE={2}'.format(d, c, gp_result_loaded.fun))\n",
    "\n",
    "    print(\"\"\"Best parameters:\n",
    "    - num_dense_layers=%d\n",
    "    - num_input_nodes=%d\n",
    "    - num_dense_nodes=%d\n",
    "    - activation=%s\n",
    "    - batch_size=%d\"\"\"  % (gp_result_loaded.x[0], gp_result_loaded.x[1],\n",
    "                            gp_result_loaded.x[2], gp_result_loaded.x[3],\n",
    "                            gp_result_loaded.x[4]))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[모델링2_GS매출] LSTM, GRU, GRU Optimization",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
